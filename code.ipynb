{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree ID3 Algorithm\n",
    "# The ID3 (Iterative Dichotomiser 3) algorithm is a decision tree algorithm that uses the concept of information gain to build the decision tree.\n",
    "\n",
    "import math\n",
    "\n",
    "# Step 1: Define the Node class for the decision tree\n",
    "class Node:\n",
    "    def _init_(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.children = {}\n",
    "\n",
    "# Step 2: Define the ID3 algorithm function\n",
    "def id3(data, target_attribute, attributes):\n",
    "    # Create a new node\n",
    "    node = Node(None)\n",
    "\n",
    "    # If all examples belong to the same class, return a leaf node with that class\n",
    "    if len(set(data[target_attribute])) == 1:\n",
    "        node.attribute = data[target_attribute].iloc[0]\n",
    "        return node\n",
    "\n",
    "    # If there are no more attributes to split on, return a leaf node with the majority class\n",
    "    if len(attributes) == 0:\n",
    "        node.attribute = data[target_attribute].value_counts().idxmax()\n",
    "        return node\n",
    "\n",
    "    # Calculate the information gain for each attribute\n",
    "    info_gains = []\n",
    "    for attribute in attributes:\n",
    "        info_gain = calculate_information_gain(data, attribute, target_attribute)\n",
    "        info_gains.append(info_gain)\n",
    "\n",
    "    # Select the attribute with the highest information gain\n",
    "    best_attribute_index = info_gains.index(max(info_gains))\n",
    "    best_attribute = attributes[best_attribute_index]\n",
    "\n",
    "    # Set the node's attribute to the best attribute\n",
    "    node.attribute = best_attribute\n",
    "\n",
    "    # Remove the best attribute from the list of attributes\n",
    "    new_attributes = attributes.copy()\n",
    "    new_attributes.remove(best_attribute)\n",
    "\n",
    "    # Create a child node for each possible value of the best attribute\n",
    "    for value in data[best_attribute].unique():\n",
    "        subset = data[data[best_attribute] == value]\n",
    "        if subset.empty:\n",
    "            # If the subset is empty, create a leaf node with the majority class\n",
    "            child_node = Node(data[target_attribute].value_counts().idxmax())\n",
    "        else:\n",
    "            # Recursively call the ID3 algorithm on the subset\n",
    "            child_node = id3(subset, target_attribute, new_attributes)\n",
    "        node.children[value] = child_node\n",
    "\n",
    "    return node\n",
    "\n",
    "# Step 3: Define the function to calculate information gain\n",
    "def calculate_information_gain(data, attribute, target_attribute):\n",
    "    # Calculate the entropy of the target attribute\n",
    "    target_entropy = calculate_entropy(data[target_attribute])\n",
    "\n",
    "    # Calculate the weighted average entropy of the attribute\n",
    "    attribute_entropy = 0\n",
    "    attribute_value_counts = data[attribute].value_counts()\n",
    "    total_examples = len(data)\n",
    "    for value, count in attribute_value_counts.items():\n",
    "        subset = data[data[attribute] == value]\n",
    "        subset_entropy = calculate_entropy(subset[target_attribute])\n",
    "        attribute_entropy += (count/total_examples) * subset_entropy\n",
    "\n",
    "    # Calculate the information gain\n",
    "    information_gain = target_entropy - attribute_entropy\n",
    "\n",
    "    return information_gain\n",
    "\n",
    "# Step 4: Define the function to calculate entropy\n",
    "def calculate_entropy(target_attribute):\n",
    "    entropy = 0\n",
    "    total_examples = len(target_attribute)\n",
    "    class_counts = target_attribute.value_counts()\n",
    "    for count in class_counts:\n",
    "        probability = count / total_examples\n",
    "        entropy -= probability * math.log2(probability)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "# Step 5: Define the function to classify a new sample using the decision tree\n",
    "def classify_sample(sample, decision_tree):\n",
    "    # Traverse the decision tree until a leaf node is reached\n",
    "    while decision_tree.children:\n",
    "        attribute = decision_tree.attribute\n",
    "        value = sample[attribute]\n",
    "        if value not in decision_tree.children:\n",
    "            # If the attribute value is not present in the decision tree, return None (unknown)\n",
    "            return None\n",
    "        decision_tree = decision_tree.children[value]\n",
    "\n",
    "    # Return the class label of the leaf node\n",
    "    return decision_tree.attribute\n",
    "\n",
    "# Step 6: Prepare the dataset for the decision tree\n",
    "# Here,\"PlayTennis\" dataset is being considered\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 7: Build the decision tree\n",
    "target_attribute = 'PlayTennis'\n",
    "attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "decision_tree = id3(df, target_attribute, attributes)\n",
    "\n",
    "# Step 8: Classify a new sample using the decision tree\n",
    "new_sample = {\n",
    "    'Outlook': 'Sunny',\n",
    "    'Temperature': 'Cool',\n",
    "    'Humidity': 'High',\n",
    "    'Wind': 'Strong'\n",
    "}\n",
    "\n",
    "classification = classify_sample(new_sample, decision_tree)\n",
    "print(\"Classification:\", classification)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
